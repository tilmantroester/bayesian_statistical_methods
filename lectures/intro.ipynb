{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import scipy.optimize\n",
    "import scipy.integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<!-- Define LaTeX macros -->\n",
       "$\\def\\E{\\operatorname{E}}$\n",
       "$\\def\\Var{\\operatorname{Var}}$\n",
       "$\\def\\Cov{\\operatorname{Cov}}$\n",
       "$\\def\\dd{\\mathrm{d}}$\n",
       "$\\def\\ee{\\mathrm{e}}$\n",
       "$\\def\\Norm{\\mathcal{N}}$\n",
       "$\\def\\Uniform{\\mathcal{U}}$\n",
       "\n",
       "<!-- MathJax needs them to be defined again for the non-inline environment -->\n",
       "$$\\def\\E{\\operatorname{E}}$$\n",
       "$$\\def\\Var{\\operatorname{Var}}$$\n",
       "$$\\def\\Cov{\\operatorname{Cov}}$$\n",
       "$$\\def\\dd{\\mathrm{d}}$$\n",
       "$$\\def\\ee{\\mathrm{e}}$$\n",
       "$$\\def\\Norm{\\mathcal{N}}$$\n",
       "$$\\def\\Uniform{\\mathcal{U}}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"# Introduction\"\n",
    "# Print title and setup TeX defs for both KaTeX and MathJax\n",
    "import bayesian_stats_course_tools\n",
    "bayesian_stats_course_tools.misc.display_markdown_and_setup_tex(title)\n",
    "\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"bayesian_stats_course_tools.light\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Statistical Methods and Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Introductions \n",
    "- Logistics\n",
    "- Structure of the course\n",
    "- Intro to Python and JupyterHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introductions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistics\n",
    "\n",
    "Slides and notebooks available on Moodle and [github](https://github.com/tilmantroester/bayesian_statistical_methods/tree/fs24).\n",
    "\n",
    "Attendance is not required but strongly recommended. I will try to keep a zoom connection open but the plan is to keep the course interactive with a lot of hands-on practice, so attending remotely (or not at all) will probably not be as useful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grades\n",
    "\n",
    "If you want credit points, the grade is going to be based on a small research project & report.\n",
    "- The project should either cover a data analysis or the theory behind a statistical tool.\n",
    "    - This can be one of the project ideas I will suggest throughout the course or some data or algorithm you find interesting and want to explore more, for example from your own research.\n",
    "- Format: like a journal article (specifically a Letter):\n",
    "    - Professional presentation, i.e. using LaTeX, nice plots\n",
    "    - Proper references and appropriate structure\n",
    "    - Page limit of 5 (excluding references)\n",
    "    - I will add a good example report on Moodle\n",
    "- Group work is allowed. Conditions:\n",
    "    - Max group size: 5\n",
    "    - Everyone in the group gets the same grade\n",
    "    - Everyone needs to contribute to both the report and the analysis\n",
    "    - The report needs to include a contribution statement that briefly describes what each member has done\n",
    "\n",
    "Deadline is 2024/07/19 at 23:59 CEST."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structure of the course\n",
    "\n",
    "- Lesson, work on exercises, discuss solutions\n",
    "- To get most out of the course, have a look at the material and exercises **before** the lecture\n",
    "- Learning by doing: we will implement many of the basic methods ourselves to get an intuition for how they work\n",
    "    - After that using well-developed and robust libraries is usually preferable\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Working in teams is encouraged\n",
    "- Be ready for Clicker questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feedback is always welcome!\n",
    "    - EduApp: Course channel \"Feedback\"\n",
    "    - Anonymous Google form (link on Moodle)\n",
    "    - Email\n",
    "    - In-person\n",
    "    - Official course evaluation on the last day of the course: Friday 14 June at 16:00"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is this course about?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical inference\n",
    "\n",
    "Statistical inference is concerned with drawing conclusions from data about quantities that are not observed. \n",
    "As a very simple example you could think of an Olympic sprinter and you urgently want to know their average speed. However, you only know the distance and have measured the time, where the measured time is subject to uncertainty. The measured time is your data and is exact. The way it is generated, however, contains uncertainty. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Bayesian data analysis\n",
    "\n",
    "Bayesian statistics provides a framework to make inference about the world by combining data with prior knowledge.\n",
    "\n",
    "The core of Bayesian data analyses is coming up with a probabilistic model of the world. \n",
    "These models describe both the observable and unobservable quantities of a problem in probabilistic terms.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Let's go back to the sprinter example: we do have an idea about running speeds at the Olympics we can use as our prior knowledge, for example, we can know that it for sure lies in a certain range. \n",
    "\n",
    "Modelling the data generating process in a probabilistic way, we can add the uncertainty in this process and evaluate it for the measured time (what is the probability to measure this time given the speed and our reaction time). \n",
    "\n",
    "This way, we can arrive at a distribution for the speed that tells us the most likely value, the mean value or give a probability that the true speed lies in a certain range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example. Imagine you want to know whether it rains on a mountain because your friend is on a hike and is planning to visit you right after. There is a weather station on the mountain but unfortunately, the rain sensor is broken. \n",
    "\n",
    "The available data from the weather station are:\n",
    "- cloud cover\n",
    "- humidity and \n",
    "- wind speed\n",
    "\n",
    "Additionally, it is known for this region that it generally rains on 30% of the days. \n",
    "\n",
    "Now we need to think about the data generation process and what data we expect when it rains: cloud cover, humidity and wind speed are observables that have a certain probability to take on values when it rains that are different from when it doesn't. There is a physical connection between these observables and rain but different parameter combinations can all lead to rain with different probabilities. \n",
    "\n",
    "We can't say: the humidity is 80%, so it rains. \n",
    "\n",
    "But we can know, either from past experience or from a weather simulation: if the humidity lies in a certain range, it is more likely to rain. \n",
    "\n",
    "Likewise, clouds hint towards rain, but there can also be clouds and no rain - observing clouds just increases the probability that there is rain. \n",
    "\n",
    "The probability distributions of the different observables when it rains are our probabilistic model we can describe mathematically with distributions and probabilities.\n",
    "\n",
    "The knowledge that the probability for rain in general is 30% is our prior knowledge. All information is in probabilites and distributions for the different parameters.\n",
    "\n",
    "From all these (general, could be used with data from any other point in time) probabilites combined with the new data, we can get a probability for rain or a chance of rain given these data. \n",
    "\n",
    "It's not a binary value yes/no but a probability again because there is uncertainty in the data generating process, our model, and in the prior knowledge. This also gives you a way of saying, how certain you can be that it rains or not. \n",
    "\n",
    "After analyzing today’s data, you calculate the probability of rain to be 50%. What does this tell you about the situation and what should you do?\n",
    "\n",
    "A) You can’t be certain whether it will rain, so be ready for either outcome and prepare a cup of tea. The 50% probability reflects high uncertainty.\n",
    "\n",
    "B) There's an equal chance of rain or no rain, so it's best to ignore the data and wait for more.\n",
    "\n",
    "C) With 50% probability, it’s more likely to rain, so definitely expect rain.\n",
    "\n",
    "D) A 50% probability is too low to expect rain, so your friend is going to arrive dry and warm. \n",
    "\n",
    "Bayesian inference provides a quantified level of uncertainty rather than a definitive answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian workflow\n",
    "#### 1. Build a model\n",
    "- The model should describe the data-generating process that gave rise to the observed data. \n",
    "- For example, not only predict the mean, but also the uncertainty in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 2. Fit the model to the data\n",
    "- Condition our probabilistic model on the observed data \n",
    "- Obtain the posterior distribution: the probability distribution of the unobserved quantities of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 3. Check the model\n",
    "- Do the results make sense?\n",
    "- Could our model have produced data like those we have observed?\n",
    "- If not, go back to step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Think in distributions\n",
    "\n",
    "In Bayesian statistics, the only thing that is exactly known are the observed data, everything else is uncertain.\n",
    "To capture the complete uncertainty structure, we work with probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Computational statistics\n",
    "\n",
    "Outside of simple models and special cases, our models will likely rely on numerical methods. \n",
    "This is especially the case in Bayesian data analysis, where drawing samples from complex distributions is often a key part of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Monte-Carlo simulation\n",
    "\n",
    "Once our models become complex, there are usually no analytic solutions any more. \n",
    "But we can often still _simulate_ the model and work with the simulated output to make inferences.\n",
    "\n",
    "Much of statistical inference is about evaluating integrals. Usual integration routines do not work most of the time. For example, because the dimensionality is too high, the boundary conditions are complicated, or we cannot evaluate the integrands explicitly.\n",
    "\n",
    "Using Monto-Carlo sampling, these problems can often be solved. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Literature\n",
    "\n",
    "- Practical Statistics for Astronomers, Wall, 2012 [ETH library](https://eth.swisscovery.slsp.ch/permalink/41SLSP_ETH/lshl64/alma99117170816205503). Short, with a focus on practical applications. Many of the examples and exercises are from astrophysics but are generally applicable, especially for the physical sciences, which often come a bit short in general statistics textbooks. Solutions and data sets are [available online](https://www.astro.ubc.ca/people/jvw/ASTROSTATS/pracstats_web_ed2.html).\n",
    "- Bayesian Data Analysis, Gelman, 2013 [ETH library](https://eth.swisscovery.slsp.ch/permalink/41SLSP_ETH/lshl64/alma99117222397805503), [Link](http://www.stat.columbia.edu/~gelman/book/). The title says it all.\n",
    "- Information Theory, Inference, and Learning Algorithms, MacKay, 2003 [Link](http://www.inference.org.uk/itprnn/book.pdf). Heavy on the information theory but also covers inference methods nicely. The exercises come with solutions.\n",
    "- Weighing the odds, a course in probability and statistics, Williams, 2001 [ETH library](https://eth.swisscovery.slsp.ch/permalink/41SLSP_ETH/lshl64/alma99117170967205503). A good introduction to probability theory and statistics with a high level of mathematical rigour.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python, Jupyter notebooks, and JupyterLab\n",
    "\n",
    "The course focusses on computational methods to do data analysis with Bayesian statistics.\n",
    "\n",
    "We will be using Python. There are other options, such as R and Julia, but once the models become more complex, Python has a much larger ecosystem available. \n",
    "For example astrophysics software or deep learning libraries.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### Jupyter notebooks\n",
    "\n",
    "A key part of a statistical analysis is understanding your data.\n",
    "Data exploration and visualisation is made easy by using Jupyter notebooks, which allow combining code, visualisations, and documentation in one place. \n",
    "\n",
    "They are not good for complex modelling however. Once your code goes beyond some simple data analysis and plotting, splitting the modelling code into standalone modules and packages makes things more robust and maintainable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### JupyterLab\n",
    "\n",
    "[JupyterLab](https://jupyterlab.readthedocs.io) is an environment that centres around editing notebooks in your browser but can do a lot more as well. For example, it provides debugging and version control interfaces, access to a terminal, etc. \n",
    "\n",
    "ETH provides an instance of JupyterLab for everyone in the course. \n",
    "This is an online development environment and comes with all the necessary packages installed. \n",
    "Changes you make will persist throughout the course. \n",
    "If you set up version control, it is easy to synchronise your JupyterLab instance with a local copy on your own device. \n",
    "\n",
    "You are free to use your own setup as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using JupyterLab\n",
    "\n",
    "If you are seeing this in the course JupyterLab, you are probably in the directory with the course materials:\n",
    "\n",
    "<img src=\"../assets/jupyterlab_landing.png\" height=\"200\">\n",
    "\n",
    "To make your life easier later on with version control, go up one level in the directory structure and make your own directory for the code you are going to write in this course:\n",
    "\n",
    "<img src=\"../assets/jupyterlab_toplevel_annotated.png\" height=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### On your own device\n",
    "\n",
    "All the materials can be access outside of JupyterLab as well. The repository with the course materials can be found [on github](https://github.com/tilmantroester/bayesian_statistical_methods/tree/fs2023).\n",
    "\n",
    "To set up your own computing environment I strongly recommend anaconda. Either using [miniconda](https://docs.conda.io/en/latest/miniconda.html) or the much faster [mamba](https://mamba.readthedocs.io/en/latest/installation.html#install-script) implementation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful extensions\n",
    "\n",
    "Two very useful JupyterLab extensions are enabled on the ETH instance: debugging and version control with git.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Debugging\n",
    "\n",
    "Any code ever written has bugs. Do not trust anyone that claims their code does not contain bugs. That includes yourself!\n",
    "\n",
    "A common approach to debugging is the sprinkle `print` statements throughout the code and try to figure out when something does not work as it should.\n",
    "\n",
    "What are some reasons why this approach might be sub optimal?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The alternative is using a debugger.\n",
    "\n",
    "A debugger allows to\n",
    "- Step through a program line-by-line\n",
    "- Set breakpoints, so the execution automatically pauses when reaching the breakpoint\n",
    "- Inspect the values of variables while the program is running and evaluate expressions based on them\n",
    "\n",
    "One of the biggest downsides to using debugger used to be the set up. But JupyterLab allows [debugging](https://jupyterlab.readthedocs.io/en/latest/user/debugger.html\n",
    ") of notebook cells, without having to setup `pdb`, `gdb`, etc. \n",
    "\n",
    "Debuggers built into other tools, such as [VS Code](https://code.visualstudio.com/), are even more powerful, with features such as [conditional breakpoints](https://code.visualstudio.com/Docs/editor/debugging#_advanced-breakpoint-topics).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![jupyterlab debugger](../assets/jupyterlab_debug_annotated.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "#### Version control\n",
    "\n",
    "If you are already familiar with version control and git, great! If not and your version control looks something like\n",
    "\n",
    "- `my_great_research_project.py`\n",
    "- `my_great_research_project_ver2.py`\n",
    "- `my_great_research_project_ver3.py`\n",
    "- `my_great_research_project_final.py`\n",
    "- `my_great_research_project_really_final.py`\n",
    "- `my_great_research_project_really_really_final.py`\n",
    "\n",
    "I suggest [this introduction](https://learn.microsoft.com/en-us/training/paths/intro-to-vc-git/). Knowing how to use version control like git is essential if you work on code (or reports) together with other people. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "To use git on JupyterLab you can use either the command line interface by opening a terminal or the graphical interface provided by JupyterLab:\n",
    "\n",
    "- Clone an existing repository:\n",
    "    1. Create a repository on your provider of choice (github, gitlab, bitbucket, etc)\n",
    "    2. On JupyterLab, `Git->Clone a Repository`. \n",
    "- Initialise an empty repository on JupyterLab:\n",
    "    1. `Git->Initialize a Repository`\n",
    "    2. If you want to synchronise with a repository outside of JupyterLab, add the remote: `Git->Manage Remote Repositories`\n",
    "\n",
    "Once the repository is set up on JupyterLab, you can add files by right-clicking on it and selecting `Git->Add` from the context menu.\n",
    "\n",
    "Opening the git pane on the left allows you to see the files with changes, look at the diffs, stage/unstage files, and commit the changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![git interface](../assets/jupyterlab_git_annotated.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "1. Create a new directory at the top of the JupyterLab file system\n",
    "2. Create a new Python notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Obtain an estimate of the value of $\\pi$\n",
    "    - From the definition in `numpy`\n",
    "    - Using an analytic series expansion: $\\pi = 4 \\sum_{k=0}^\\infty \\frac{(-1)^{k}}{2k + 1}$\n",
    "    - Using a Monte-Carlo estimate: \n",
    "        1. Sample $n$ points uniformly on the unit square using `numpy.random.uniform`\n",
    "        2. Count the number $n_{<r}$ of points with distance $r = \\sqrt{x^2+y^2} \\leq 1$\n",
    "        3. Compare the fraction $\\frac{n_{<r}}{n}$ to the ratio of the area of a quadrant of a disc to the area of the square to derive an estimate of $\\pi$\n",
    "    - Bonus: Repeat for (hyper) cube and (hyper) ball in 3 or more dimensions. How does the number of samples required to get a robust estimate of $\\pi$ change with the number of dimensions? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Use the debugger to step through some iterations of your code.\n",
    "\n",
    "5. Create plots showing the estimated value as the number of terms in the series expansion and the number of Monte-Carlo samples is varied"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your python package\n",
    "\n",
    "The goal of this course is for you to build a toolbox with statistical and computational methods that you can use in your future data analyses. \n",
    "\n",
    "For that toolbox to be useful it needs to contain reusable code. Notebooks are great for quick development and data exploration but terrible for reusable and maintainable code. \n",
    "As soon as you think about copy & pasting some piece of code from one notebook to another (or within the same notebook), you should instead consider putting that piece of code into your toolbox. \n",
    "\n",
    "This toolbox can be made into a python package, so that you can import it where ever you need it.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, under `course_tools` in the course repository is a small python package with some helper functions, for example for creating the slides. \n",
    "\n",
    "The package can be installed from the `course_tools` directory by calling `pip install --user --editable .`\n",
    "\n",
    "I can then `import` the package like any other python package and use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import bayesian_stats_course_tools\n",
    "bayesian_stats_course_tools.misc.load_tex_defs()\n",
    "\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"bayesian_stats_course_tools.light\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To create your own package, have a look at the example in `course_tools` and the documentation at https://packaging.python.org/en/latest/tutorials/packaging-projects/.\n",
    "\n",
    "The key files are\n",
    "- The `pyproject.toml` file, which specifies that this is a python package\n",
    "- The `src/bayesian_stats_course_tools/__init__.py`, which makes `bayesian_stats_course_tools` a python module that can be imported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "title": "Introduction"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
